{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "In a large text corpus, some words will be very present (e.g. “the”, “a”, “is” in English) hence carrying very little meaningful information about the actual contents of the document. If we were to feed the direct count data directly to a classifier those very frequent terms would shadow the frequencies of rarer yet more interesting terms.\n",
    "\n",
    "In order to re-weight the count features into floating point values suitable for usage by a classifier it is very common to use the tf–idf transform.\n",
    "\n",
    "**Tf** means **term-frequency** while tf–idf means term-frequency times **inverse document-frequency**\n",
    "\n",
    "* http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting\n",
    "* https://www.coursera.org/learn/language-processing/lecture/vlmT5/feature-extraction-from-text\n",
    "* https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"Este é o primeiro documento\", \"Este é o segundo documento\", \"Este é o terceiro terceiro documento\", \n",
    "          \"isso é um documento?\", \"e o quinto.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "bow = tf_idf_vectorizer.fit_transform(corpus)\n",
    "tf_idf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bow.toarray(), columns=tf_idf_vectorizer.get_feature_names(), index=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_punctuation = set(stopwords.words('portuguese') + list(punctuation))\n",
    "def tokenizer(document):\n",
    "    return tokenize.word_tokenize(document, language='portuguese')\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(tokenizer=tokenizer, stop_words=stopwords_punctuation)\n",
    "bow = tf_idf_vectorizer.fit_transform(corpus)\n",
    "pd.DataFrame(bow.toarray(), columns=tf_idf_vectorizer.get_feature_names(), index=corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
